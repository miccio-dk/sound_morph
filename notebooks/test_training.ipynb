{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "explicit-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "significant-burning",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rmicci18/miniconda3/envs/sound_morph/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import librosa as lr\n",
    "import torch\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from scipy.signal.windows import hann\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, EarlyStopping\n",
    "\n",
    "from datasets.nsynth_datamodule import NsynthDataModule\n",
    "from models.cvae_resnet import CvaeResnet\n",
    "from models.cvae_inception import CvaeInception\n",
    "from models.vae_inception import VaeInception\n",
    "from models.vae_inception_custom import VaeInceptionCustom\n",
    "\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "protected-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIGS\n",
    "\n",
    "train_configs = {\n",
    "    'type': 'vae_cstm',\n",
    "    'descr': 'decay',\n",
    "    'num_workers': 16,\n",
    "    'batch_size': 64,\n",
    "    'max_epochs': 10000,\n",
    "    'patience': 300,\n",
    "    'trainer_kwargs': {\n",
    "        'gpus': '1',\n",
    "        'accelerator': None,\n",
    "        'num_nodes': 1,\n",
    "        'precision': 32,\n",
    "        'accumulate_grad_batches': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "ds_configs = {\n",
    "    'dataset_path': '/data/riccardo_datasets',\n",
    "    'feature': 'spec',\n",
    "    'feature_params': {\n",
    "        'win_length': 256,\n",
    "        'hop_length': 64,\n",
    "        'window': hann(256).tolist()\n",
    "    },\n",
    "    'n_fft': 510,\n",
    "    'ds_kwargs': {\n",
    "        'pitches': [60],\n",
    "        #'instrument_families': [0],\n",
    "        'sr': 16000,\n",
    "        'duration': 1.02\n",
    "    }\n",
    "}\n",
    "\n",
    "m_configs_incept = {\n",
    "    'optim': 'yogi',\n",
    "    'optim_kwargs': {\n",
    "        'lr': 1e-3,\n",
    "    },\n",
    "    'lr_scheduler': {\n",
    "        'factor': 0.1, \n",
    "        'patience': 100,\n",
    "        'cooldown': 30,\n",
    "        'min_lr': 1e-5\n",
    "    },\n",
    "    'db_kwargs': {\n",
    "        'amin': 1e-5,\n",
    "        'top_db': 90\n",
    "    },\n",
    "#    'c_labels': ['pitch'],\n",
    "    'kl_coeff': 5e-5,\n",
    "    'kl_decay': 1.,\n",
    "    'db_coeff': 1e-4,\n",
    "    'db_decay': 1.,\n",
    "    'latent_size': 64,\n",
    "    'channel_size': 2,\n",
    "    'channel_max': 128,\n",
    "    'use_inception': True,\n",
    "    'repeat_per_block': 1,\n",
    "}\n",
    "\n",
    "configs = {\n",
    "    'train': train_configs,\n",
    "    'dataset': ds_configs,\n",
    "    'model': m_configs_incept\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "verbal-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../configs/vae_small.json', 'w') as fp:\n",
    "    json.dump(configs, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "tamil-mapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_true torch.Size([1, 2, 256, 256])\n",
      "hidden_enc torch.Size([1, 128])\n",
      "mean torch.Size([1, 128]) torch.Size([1, 128])\n",
      "z torch.Size([1, 128])\n",
      "hidden_dec torch.Size([1, 128])\n",
      "x_rec torch.Size([1, 2, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 4.7255,  7.0502,  7.7187,  ...,  7.1188,  5.3107,  4.1573],\n",
       "           [ 6.5614,  3.4549,  4.7172,  ...,  2.9339,  3.5087,  4.7234],\n",
       "           [ 6.1976,  4.0059,  1.4937,  ...,  1.6084, -0.2501,  2.8330],\n",
       "           ...,\n",
       "           [ 7.2969,  6.4551,  5.9911,  ...,  3.6885,  3.3300,  2.3644],\n",
       "           [ 7.4315,  3.6635,  3.1415,  ...,  2.3514, -0.0492,  3.9194],\n",
       "           [ 5.0750,  4.8093,  3.3677,  ...,  3.1145,  3.5428, -1.3836]],\n",
       " \n",
       "          [[ 0.7958,  0.6023,  1.6776,  ...,  0.3987,  0.8204,  1.3168],\n",
       "           [-1.9202, -0.6654,  0.1256,  ..., -0.6959, -0.8270,  0.3657],\n",
       "           [ 0.7794, -0.2615,  0.3933,  ...,  0.2971, -0.4553, -0.4939],\n",
       "           ...,\n",
       "           [-1.1908, -2.2876, -1.3261,  ..., -1.2160, -2.0508, -0.9143],\n",
       "           [-0.2340, -0.1883,  0.6244,  ...,  0.7341, -1.4440,  1.2535],\n",
       "           [-2.2437, -2.0847, -1.6963,  ...,  0.7179, -1.5545, -3.0081]]]],\n",
       "        grad_fn=<SlowConvTranspose2DBackward>),\n",
       " tensor([[ 3.0922, -0.5216, -0.9163, -2.0393,  1.4468,  1.5272, -2.7165,  1.6253,\n",
       "           3.7560,  0.6967,  2.0259, -3.0764, -2.4614, -1.1870,  1.5585, -3.4720,\n",
       "          -5.5769, -1.6006, -0.9547, -5.2132, -3.7003, -0.9475, -1.1279, -0.1016,\n",
       "           2.2092,  0.1842, -3.4272, -4.9403,  1.0017, -2.4448,  4.2049, -1.7364,\n",
       "          -2.8064,  1.8912, -0.1110, -1.5806, -3.7108, -0.8353,  2.9707,  2.2785,\n",
       "          -5.2300,  0.0425, -4.4992,  1.0399, -0.7959,  1.9366, -0.3533,  1.5170,\n",
       "          -2.0265, -0.7283,  4.1724,  1.4119, -0.3509,  5.5853,  2.1349, -0.8635,\n",
       "          -2.6492, -0.3822, -0.8918, -0.7685,  2.1960, -1.9580, -0.6391,  4.8776,\n",
       "           4.2955,  0.7992, -6.1210, -3.7210, -2.9299,  4.1110, -3.1011, -4.2514,\n",
       "          -0.0120, -2.4847, -4.0508,  3.9699,  1.1845,  4.5833, -1.1796, -2.3462,\n",
       "           3.2834, -2.5017,  0.4180,  1.4400,  0.0926, -6.5273, -0.4018, -1.1053,\n",
       "          -3.3176, -4.3727,  0.1057, -1.7200, -4.2269, -0.0425, -1.1319, -2.8017,\n",
       "          -4.2931,  5.2104, -4.1858, -1.3385,  3.6101,  1.0410,  1.0625,  0.5665,\n",
       "           0.4071, -0.0803, -1.8872,  0.7581, -4.9386, -0.8764,  2.2359,  3.7874,\n",
       "          -0.1721,  0.5058,  3.7550, -1.9192,  4.0396,  4.3145, -2.7908, -1.3670,\n",
       "           2.5533,  0.3091,  0.0945, -3.7010, -0.2814, -4.8427, -0.2781,  0.4128]],\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.0847,  3.0789, -0.6976,  5.7664, -2.7500, -3.3324, -4.5722, -0.9931,\n",
       "          -0.5409, -1.1223, -4.6594,  0.0825, -3.2844,  0.4544,  4.1172, -3.3612,\n",
       "          -0.1179,  5.1548,  3.4211,  0.6536, -2.3858, -2.9428,  3.6745,  2.2573,\n",
       "          -2.2989,  4.2503, -0.1654, -2.2807,  1.0639,  2.5436,  4.1491,  4.5682,\n",
       "           1.3039,  0.7071,  1.1902, -4.3328,  0.7088, -2.7249, -3.9822, -0.1919,\n",
       "           0.7763, -1.8941, -1.7295,  5.0353,  1.1419, -0.1480,  4.0614, -0.0680,\n",
       "           2.1306, -2.6787, -1.4591, -0.9229, -0.8835,  0.3364,  1.6436,  3.8191,\n",
       "          -3.3336,  0.0189, -1.8532, -0.5046,  0.3072,  0.5703, -1.9944,  0.9349,\n",
       "          -0.5621, -0.5605, -1.7538,  0.4229, -3.3714,  0.5864,  4.3004,  2.1235,\n",
       "          -1.1456,  4.7267,  0.5303, -3.5769, -2.8573, -2.9131,  1.6978,  1.6053,\n",
       "          -0.6506, -1.5509,  1.1194, -2.5335, -4.9872, -3.4793, -4.2800,  4.6590,\n",
       "           2.8202, -5.0056, -0.4829, -0.3925,  2.1446,  1.8916,  5.3974,  7.1866,\n",
       "          -2.0817, -3.0221,  1.2980, -5.4203,  4.1388, -1.5581, -2.0187,  0.5048,\n",
       "          -2.9147, -4.9965,  2.4118,  2.3776,  3.7501, -5.0912,  1.2472, -0.7430,\n",
       "           1.7059,  0.7010, -0.6917,  2.3287, -1.3806,  3.9613,  0.4223,  0.0543,\n",
       "          -0.0506,  0.3785,  0.9114, -0.2029,  1.4722, -1.5462, -0.1536, -4.2798]],\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[ 2.5403e+00, -1.6610e+01,  4.2735e-01, -1.1896e+01,  1.6853e+00,\n",
       "           1.5698e+00, -2.8858e+00,  1.7944e+00,  3.7965e+00,  1.6093e-01,\n",
       "           1.9840e+00, -2.7665e+00, -2.9871e+00, -1.9193e+00, -8.1381e+00,\n",
       "          -3.4077e+00, -5.4457e+00,  2.7727e+00,  5.1974e+00, -2.0658e+00,\n",
       "          -3.4240e+00, -9.4490e-01,  2.8342e-01, -3.2333e-02,  2.1280e+00,\n",
       "          -8.7575e+00, -4.2067e+00, -4.7762e+00,  1.3049e+00,  2.9582e-01,\n",
       "           4.3549e+00, -1.4551e+01, -8.7043e-01,  1.7211e+00,  3.1243e-01,\n",
       "          -1.5239e+00, -3.2015e+00, -5.5696e-01,  2.8947e+00,  1.4326e+00,\n",
       "          -6.2344e+00,  3.7858e-02, -4.5239e+00, -1.6487e+01, -2.9119e+00,\n",
       "           1.0484e+00,  1.4405e+00,  1.6343e+00, -6.7261e+00, -4.3211e-01,\n",
       "           4.5491e+00,  1.2560e+00,  4.9125e-01,  5.0554e+00,  6.8869e+00,\n",
       "          -4.4473e-02, -2.4005e+00, -1.2416e+00, -1.0483e+00, -7.0718e-01,\n",
       "           1.3281e+00, -7.5125e-01, -7.6566e-01,  4.7061e+00,  4.8390e+00,\n",
       "           5.1107e-01, -4.7663e+00, -1.8993e+00, -3.0609e+00,  4.0792e+00,\n",
       "           2.2379e+00, -5.7916e+00,  7.4407e-01, -7.9241e+00, -3.7874e+00,\n",
       "           3.8726e+00,  8.4606e-01,  4.6113e+00, -2.3257e-01, -3.0318e+00,\n",
       "           3.6056e+00, -2.5914e+00, -1.2132e+00,  1.4514e+00,  1.2733e-01,\n",
       "          -6.5762e+00, -3.7393e-01, -3.9918e+00,  3.6071e-01, -4.3852e+00,\n",
       "          -1.3423e-01, -9.4752e-01, -2.8516e-01, -2.1257e+00,  1.2041e+01,\n",
       "           4.4033e+01, -4.3587e+00,  5.0480e+00, -3.1323e+00, -1.3551e+00,\n",
       "          -1.9920e+00,  1.0980e+00,  7.9672e-01,  3.9755e-01,  2.2508e-01,\n",
       "          -1.6005e-01, -7.6183e+00,  1.8047e+00, -1.2157e+01, -8.1188e-01,\n",
       "           4.1891e+00,  3.4907e+00,  2.7958e-01,  2.8967e+00,  3.0521e+00,\n",
       "          -4.6649e+00,  4.0572e+00, -2.5912e+00, -2.1001e+00, -1.1987e+00,\n",
       "           2.7869e+00,  1.4444e+00,  2.6122e+00, -5.4728e+00, -1.9134e+00,\n",
       "          -5.3389e+00, -2.9354e-01,  3.1661e-01]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_configs_incept = {\n",
    "    'optim': 'yogi',\n",
    "    'optim_kwargs': {\n",
    "        'lr': 0.0001,\n",
    "    },\n",
    "    'lr_scheduler': {\n",
    "        'factor': 0.1, \n",
    "        'patience': 100,\n",
    "        'cooldown': 30,\n",
    "        'min_lr': 1e-5\n",
    "    },\n",
    "    'db_kwargs': {\n",
    "        'amin': 1e-5,\n",
    "        'top_db': 90\n",
    "    },\n",
    "#    'c_labels': ['pitch'],\n",
    "    'kl_coeff': 5e-5,\n",
    "    'kl_decay': 1.,\n",
    "    'db_coeff': 1e-3,\n",
    "    'db_decay': 1.,\n",
    "    'latent_size': 128,\n",
    "    'channel_size': 2,\n",
    "    'channel_max': 128,\n",
    "    'use_inception': True,\n",
    "    'repeat_per_block': 1,\n",
    "}\n",
    "\n",
    "m = VaeInceptionCustom(m_configs_incept)\n",
    "x = torch.randn(1, 2, 256, 256)\n",
    "m._shared_eval(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-copying",
   "metadata": {},
   "source": [
    "## urban sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "banned-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIGS\n",
    "\n",
    "ds_configs_usnds = {\n",
    "    'dataset_path': '/data/riccardo_datasets/urban_sounds',\n",
    "    'feature': 'spec',\n",
    "    'feature_params': {\n",
    "        'win_length': 256,\n",
    "        'hop_length': 64,\n",
    "        'window': hann(256).tolist()\n",
    "    },\n",
    "    'n_fft': 510,\n",
    "    'ds_kwargs': {\n",
    "        'sr': 16000,\n",
    "        'duration': 1.02\n",
    "    }\n",
    "}\n",
    "\n",
    "configs_usnds = {\n",
    "    'train': train_configs,\n",
    "    'dataset': ds_configs_usnds,\n",
    "    'model': m_configs_incept\n",
    "}\n",
    "configs_usnds['train']['trainer_kwargs']['gpus'] = '1'\n",
    "configs_usnds['train']['num_workes'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "paperback-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../configs/test2_usnds.json', 'w') as fp:\n",
    "    json.dump(configs_usnds, fp, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-relation",
   "metadata": {},
   "source": [
    "## proper training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "enclosed-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger\n",
    "log_name = '{}_{}'.format(CvaeInception.model_name, train_configs['descr'])\n",
    "logger = TensorBoardLogger('logs', name=log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "maritime-cattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rmicci18/miniconda3/envs/sound_morph/lib/python3.8/site-packages/torch/functional.py:515: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607369981906/work/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "# init data loader\n",
    "dm = NsynthDataModule(ds_configs, num_workers=train_configs['num_workers'], batch_size=train_configs['batch_size'])\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=train_configs['patience'])\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "# train!\n",
    "trainer = pl.Trainer(\n",
    "#    weights_summary='full',\n",
    "#    overfit_batches=1,\n",
    "#    terminate_on_nan=False,\n",
    "#    gradient_clip_val=0.5,\n",
    "    max_epochs=train_configs['max_epochs'],\n",
    "    callbacks=[early_stop, lr_monitor],\n",
    "    logger=logger,\n",
    "    **configs['train']['trainer_kwargs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-accuracy",
   "metadata": {},
   "source": [
    "## quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "female-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using 5 batch(es).\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | encoder   | Encoder | 3.8 M \n",
      "1 | fc_mu     | Linear  | 8.3 K \n",
      "2 | fc_logvar | Linear  | 8.3 K \n",
      "3 | fc_rep    | Linear  | 8.7 K \n",
      "4 | decoder   | Decoder | 2.2 M \n",
      "--------------------------------------\n",
      "5.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.9 M     Total params\n",
      "/home/rmicci18/miniconda3/envs/sound_morph/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: You requested to overfit but enabled test/val dataloader shuffling. We are turning it off for you.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rmicci18/miniconda3/envs/sound_morph/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: You requested to overfit but enabled training dataloader shuffling. We are turning it off for you.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df18f2861114a73a00db93a22dd105d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81\n",
      "0.7290000000000001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7290000000000001\n",
      "0.6561000000000001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6561000000000001\n",
      "0.5904900000000002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5904900000000002\n",
      "0.5314410000000002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5314410000000002\n",
      "0.47829690000000014\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47829690000000014\n",
      "0.43046721000000016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43046721000000016\n",
      "0.38742048900000015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38742048900000015\n",
      "0.34867844010000015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34867844010000015\n",
      "0.31381059609000017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31381059609000017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = NsynthDataModule(ds_configs, num_workers=16, batch_size=8)\n",
    "trainer = pl.Trainer(fast_dev_run=5, gpus='1')\n",
    "trainer = pl.Trainer(max_epochs=10, overfit_batches=1, gpus='1')\n",
    "trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-anime",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
